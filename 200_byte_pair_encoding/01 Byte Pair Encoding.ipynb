{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9503f8a8-9e55-4b04-83c5-0ef30de0280c",
   "metadata": {},
   "source": [
    "# 2. Byte Pair Encoding (BPE)\n",
    "\n",
    "Byte pair encoding은 1994년에 제안된 데이터 압축 알고리즘이며, subword 알고리즘으로 응용이 되었습니다. <br>\n",
    "알고리즘은 가장 많이 사용되는 pair of bytes를 사용하지 않는 하나의 단어로 바꾸는 것이며, 이것을 n번에 걸쳐서 반복적으로 줄이게 됩니다. <br>\n",
    "예를 들어서 ...\n",
    "\n",
    "- `aaabdaaabac` 의 경우 `aa` 가 가장 많이 나오며, 사용하지 않는 단어 Z 로 변환합니다. \n",
    "- 변환된 단어는 `ZabdZabac` 이며, 다시 가장 빈번도가 높은 pair of bytes는 `ab` 이며 `Y`로 변환한다면 `ZYdZYac`로 압축될수 있습니다. \n",
    "\n",
    "\n",
    "\n",
    "## 2.1 Build Dictionary \n",
    "\n",
    "먼저 dictionary 를 만들어야 하며, 이는 기존의 word 단위의 dictionary 와 동일합니다.\n",
    "\n",
    "- 데이터: corpus는 네이버에서 스파이더맨 (노 웨이 홈)의 평론가의 코멘트, 그리고 나무위키의 내용을 가져왔습니다.\n",
    "- preprocess 함수: konlpy를 통해서 필요없는 품사들을 제거\n",
    "- build_dictionary 함수: word 단위의 dictionary 를 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a4c2550e-ab34-44dd-b94a-3f9fff9823fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('스', '파', '이', '더', '맨', '\\x00'): 4,\n",
       " ('슈', '퍼', '맨', '\\x00'): 2,\n",
       " ('배', '트', '맨', '\\x00'): 3,\n",
       " ('아', '이', '언', '맨', '\\x00'): 2,\n",
       " ('올', '해', '\\x00'): 1,\n",
       " ('최', '고', '\\x00'): 2,\n",
       " ('영', '화', '\\x00'): 2,\n",
       " ('아', '닐', '까', '\\x00'): 1,\n",
       " ('생', '각', '\\x00'): 1,\n",
       " ('함', '\\x00'): 1,\n",
       " ('파', '\\x00'): 1,\n",
       " ('프', '롬', '\\x00'): 1,\n",
       " ('홈', '\\x00'): 1,\n",
       " ('M', 'C', 'U', '\\x00'): 1,\n",
       " ('v', 's', '\\x00'): 1,\n",
       " ('스', '토', '리', '\\x00'): 1,\n",
       " ('진', '부', '하', '기', '\\x00'): 1,\n",
       " ('짝', '\\x00'): 1,\n",
       " ('없', '음', '\\x00'): 1,\n",
       " ('그', '리', '고', '\\x00'): 1,\n",
       " ('어', '제', '\\x00'): 3,\n",
       " ('I', 'M', 'A', 'X', '\\x00'): 2,\n",
       " ('봤', '는', '데', '\\x00'): 3,\n",
       " ('쩔', '어', '\\x00'): 3,\n",
       " ('영', '화', '관', '\\x00'): 2,\n",
       " ('ㅋ', 'ㅋ', '\\x00'): 1,\n",
       " ('개', '\\x00'): 1,\n",
       " ('ㅋ', 'ㅋ', 'ㅋ', 'ㅋ', '\\x00'): 1,\n",
       " ('또', '\\x00'): 1,\n",
       " ('보', '고', '\\x00'): 1,\n",
       " ('싶', '다', '\\x00'): 1,\n",
       " ('스', '파', '이', '더', '\\x00'): 1,\n",
       " ('짱', '\\x00'): 2,\n",
       " ('슈', '가', '\\x00'): 2,\n",
       " ('슈', '퍼', '마', '켓', '\\x00'): 1,\n",
       " ('배', '트', '\\x00'): 2,\n",
       " ('걸', '\\x00'): 1,\n",
       " ('아', '이', '언', '돔', '\\x00'): 1,\n",
       " ('ㅋ', 'ㅋ', 'ㅋ', '\\x00'): 1,\n",
       " ('스', '파', '\\x00'): 1,\n",
       " ('슈', '퍼', '\\x00'): 1,\n",
       " ('아', '이', '언', '\\x00'): 1,\n",
       " ('ㄹ', 'ㅇ', '\\x00'): 2,\n",
       " ('ㅋ', '\\x00'): 1,\n",
       " ('ㅠ', 'ㅠ', '\\x00'): 2,\n",
       " ('돈', '\\x00'): 1,\n",
       " ('날', '림', '\\x00'): 1}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def preprocess(text) -> List[str]:\n",
    "    morphs = okt.pos(text)\n",
    "    tokens = []\n",
    "    for word, pos in morphs:\n",
    "        if pos in ('Josa', 'Punctuation', 'Foreign'):\n",
    "            continue\n",
    "        \n",
    "        tokens.append(word)\n",
    "    return tokens\n",
    "    \n",
    "\n",
    "def build_dictionary(corpus: List[str], end_token='\\0') -> Dict[str, int]:\n",
    "    dictionary = defaultdict(int)\n",
    "    for line in corpus:\n",
    "        tokens = preprocess(line)\n",
    "        for token in tokens:\n",
    "            if not token:\n",
    "                continue\n",
    "            dictionary[tuple(list(token) + [end_token])] += 1\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "corpus = [\n",
    "    \"스파이더맨, 슈퍼맨, 배트맨, 아이언맨은 올해 최고의 영화가 아닐까 생각함\",\n",
    "    \"스파이더맨 파프롬홈은 MCU 최고의 영화이다\",\n",
    "    \"슈퍼맨 vs 배트맨의 스토리는 진부하기 짝이 없음. 그리고 어제 IMAX 스파이더맨봤는데 쩔어!\",\n",
    "    \"어제 스파이더맨을 IMAX 영화관에서 봤는데.. ㅋㅋ 개쩔어.ㅋㅋㅋㅋ 아이언맨 또 영화관에서 보고 싶다\",\n",
    "    \"스파이더짱, 슈가짱, 슈퍼마켓, 배트걸, 아이언돔 ㅋㅋㅋ\",\n",
    "    \"스파, 슈가, 슈퍼, 배트, 아이언 ㄹㅇ쩔어! ㅋ\",\n",
    "    \"어제 배트맨 봤는데 ㅠㅠ ㄹㅇ 돈날림ㅠㅠ!!\"\n",
    "]\n",
    "\n",
    "dictionary = build_dictionary(corpus)\n",
    "dict(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec305a-5f44-4b39-ba67-63a983b3e72f",
   "metadata": {},
   "source": [
    "## 2.2 Byte Pair Encoding \n",
    "\n",
    "알고리즘의 순서는 다음과 같습니다. \n",
    "\n",
    "1. 모든 pair of bytes에 대해서 count 계산을 합니다. \n",
    "2. 가장 빈도수가 높은 pair of byte 를 찾습니다.\n",
    "3. 해당 빈도수 높은 pair of byte를 기존 vocabulary keys 에서 포함되어 있는 단어를 찾습니다. \n",
    "    - 만약 포함되어 있는 단어를 찾으면 해당 빈도수 높은 단어로 대체를 하고 기존 단어는 vocabulary 에서 제외 시킵니다. \n",
    "    - 만약 찾지 못한다면 기존 단어를 그대로 vocabulary 에 넣습니다. \n",
    "4. 다시 1번으로 돌아거 n번만큼 반복합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "40334244-882e-4fee-8f9a-caa297ed30f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('스파이더맨\\x00',): 4,\n",
       " ('슈퍼맨\\x00',): 2,\n",
       " ('배트맨\\x00',): 3,\n",
       " ('아이언맨\\x00',): 2,\n",
       " ('올해\\x00',): 1,\n",
       " ('최고\\x00',): 2,\n",
       " ('영화\\x00',): 2,\n",
       " ('아닐까\\x00',): 1,\n",
       " ('생각\\x00',): 1,\n",
       " ('함\\x00',): 1,\n",
       " ('파\\x00',): 1,\n",
       " ('프롬', '\\x00'): 1,\n",
       " ('홈', '\\x00'): 1,\n",
       " ('M', 'C', 'U', '\\x00'): 1,\n",
       " ('v', 's', '\\x00'): 1,\n",
       " ('스', '토', '리', '\\x00'): 1,\n",
       " ('진', '부', '하', '기', '\\x00'): 1,\n",
       " ('짝', '\\x00'): 1,\n",
       " ('없', '음', '\\x00'): 1,\n",
       " ('그', '리', '고\\x00'): 1,\n",
       " ('어제\\x00',): 3,\n",
       " ('IMAX\\x00',): 2,\n",
       " ('봤는데\\x00',): 3,\n",
       " ('쩔어\\x00',): 3,\n",
       " ('영화관\\x00',): 2,\n",
       " ('ㅋㅋ\\x00',): 1,\n",
       " ('개', '\\x00'): 1,\n",
       " ('ㅋㅋ', 'ㅋㅋ\\x00'): 1,\n",
       " ('또', '\\x00'): 1,\n",
       " ('보', '고\\x00'): 1,\n",
       " ('싶', '다', '\\x00'): 1,\n",
       " ('스파이더', '\\x00'): 1,\n",
       " ('짱\\x00',): 2,\n",
       " ('슈가\\x00',): 2,\n",
       " ('슈퍼', '마', '켓', '\\x00'): 1,\n",
       " ('배트\\x00',): 2,\n",
       " ('걸', '\\x00'): 1,\n",
       " ('아이언', '돔', '\\x00'): 1,\n",
       " ('ㅋㅋ', 'ㅋ\\x00'): 1,\n",
       " ('스파', '\\x00'): 1,\n",
       " ('슈퍼', '\\x00'): 1,\n",
       " ('아이언', '\\x00'): 1,\n",
       " ('ㄹㅇ\\x00',): 2,\n",
       " ('ㅋ\\x00',): 1,\n",
       " ('ㅠㅠ\\x00',): 2,\n",
       " ('돈', '\\x00'): 1,\n",
       " ('날', '림', '\\x00'): 1}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pairs(dictionary, end_token='\\0'):\n",
    "    pairs = defaultdict(int)\n",
    "    for word, freq in dictionary.items():\n",
    "        i = 0  # len(word) == 1 인 경우 i의 값이 초기화가 안되기 때문에 필요\n",
    "        for i in range(len(word)-1):\n",
    "            pairs[word[i], word[i+1]] += freq\n",
    "    return pairs\n",
    "\n",
    "def search_merge_vocab(pair, dictionary, end_token='\\0') -> Dict[str, int]:\n",
    "    vocab = {}\n",
    "    pair_word = ''.join(pair)\n",
    "    \n",
    "    for word in dictionary:    \n",
    "        i = 0\n",
    "        flag = False\n",
    "        key = list()\n",
    "        \n",
    "        while i < (len(word)):\n",
    "            if (pair[0] == word[i]) and pair[1] == word[i+1]:\n",
    "                key.append(pair_word)\n",
    "                i += 2\n",
    "                flag = True\n",
    "            else:\n",
    "                key.append(word[i])\n",
    "                i += 1\n",
    "                \n",
    "        vocab[tuple(key)] = dictionary[word]\n",
    "    return vocab\n",
    "\n",
    "def bpe(dictionary, n_iter=10):\n",
    "    for i in range(n_iter):\n",
    "        pairs = get_pairs(dictionary)\n",
    "        most_freq_pair = max(pairs, key=pairs.get)\n",
    "        dictionary = search_merge_vocab(most_freq_pair, dictionary)\n",
    "    return dictionary\n",
    "bpe(dictionary, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb7d87-5d8f-4db0-982d-1536f431ed36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
